library(data.table)
library(rgdal)
library(rgeos)
library(ggplot2)
library(ggrepel)
library(sf)
library(sp)
library(ggpubr)
library(dplyr)
library(tidyr)
library(scales)
library(tidyverse)
library(lubridate)
library(gtools)
library(foreign)
library(ggmap)
library(maps)
library(gganimate)
library(gifski)
library(transformr)
library(tmap)
library(raster)
library(exactextractr)
library(matrixStats)
load("C:/Users/jmjimenez/Dropbox/My-Research/Guerillas_Development/2-Data/Salvador/temp/segm_info_onu91_shp_v3.RData")
res(cocoa)
res(elevation2)
res(nl13)
tm_shape(slvShp_segm) +
tm_borders()+
tm_shape(controlShp) +
tm_borders(col='red', lwd = 2, lty = "solid", alpha = NA) +
tm_add_legend(type="line", col="red", lwd=10, title="FMLN-Dominated Zone")+
tm_layout(legend.outside = TRUE, legend.outside.position = "left", legend.outside.size=0.15, legend.title.size =1, frame = FALSE)
tm_shape(slvShp) +
tm_borders()+
tm_shape(controlShp) +
tm_borders(col='red', lwd = 2, lty = "solid", alpha = NA) +
tm_add_legend(type="line", col="red", lwd=10, title="FMLN-Dominated Zone")+
tm_layout(legend.outside = TRUE, legend.outside.position = "left", legend.outside.size=0.15, legend.title.size =1, frame = FALSE)
tm_shape(slvShp) +
tm_borders()+
tm_shape(controlShp) +
tm_borders(col='red', lwd = 2, lty = "solid", alpha = NA) +
tm_add_legend(type="line", col="red", lwd=10, title="FMLN-Dominated Zone")
tm_shape(slvShp) +
tm_borders()+
tm_shape(controlShp) +
tm_borders(col='red', lwd = 2, lty = "solid", alpha = NA) +
tm_add_legend(type="line", col="red", lwd=10, title="FMLN-Dominated Zone")+
tm_layout(frame = FALSE)
tm_shape(slvShp) +
tm_borders()+
tm_shape(controlShp) +
tm_borders(col='red', lwd = 2, lty = "solid", alpha = NA) +
tm_add_legend(type="line", col="red", lwd=10, title="FMLN-Dominated Zone")+
tm_layout(frame = FALSE)
tmap_save(filename="C:/Users/jmjimenez/Dropbox/Apps/Overleaf/GD-draft-slv/plots/fmln_dominated.pdf")
tm_shape(slvShp_segm_info) +
tm_polygons(col='high_elev', title='Elevation', palette="-RdYlGn")+
tm_shape(controlShp) +
tm_borders(col='red', lwd = 2, lty = "solid", alpha = NA) +
tm_add_legend(type="line", col="red", lwd=10, title="FMLN-Dominated Zone")+
tm_layout(legend.outside = TRUE, legend.outside.position = "left", legend.outside.size=0.15, legend.title.size =1, frame = FALSE)
tm_shape(slvShp_segm_info) +
tm_polygons(col='mean_elev2', title='Altitude', palette="-RdYlGn")+
tm_shape(controlShp) +
tm_borders(col='red', lwd = 2, lty = "solid", alpha = NA) +
tm_add_legend(type="line", col="red", lwd=10, title="FMLN-Dominated Zone")+
tm_layout(legend.outside = TRUE, legend.outside.position = "left", legend.outside.size=0.15, legend.title.size =1, frame = FALSE)
tmap_save(filename="C:/Users/jmjimenez/Dropbox/Apps/Overleaf/GD-draft-slv/plots/elev_segm.pdf", dpi=100)
tm_shape(slvShp_segm_info) +
tm_polygons(col='high_elev', title='Altitude', palette="-RdYlGn")+
tm_shape(controlShp) +
tm_borders(col='red', lwd = 2, lty = "solid", alpha = NA) +
tm_add_legend(type="line", col="red", lwd=10, title="FMLN-Dominated Zone")+
tm_layout(legend.outside = TRUE, legend.outside.position = "left", legend.outside.size=0.15, legend.title.size =1, frame = FALSE)
tmap_save(filename="C:/Users/jmjimenez/Dropbox/Apps/Overleaf/GD-draft-slv/plots/elev_high_segm.pdf", dpi=100)
library(data.table)
library(rgdal)
library(rgeos)
library(ggplot2)
library(ggrepel)
library(sf)
library(sp)
library(ggpubr)
library(dplyr)
library(tidyr)
library(scales)
library(tidyverse)
library(lubridate)
library(gtools)
library(foreign)
library(ggmap)
library(maps)
library(gganimate)
library(gifski)
library(transformr)
library(tmap)
library(raster)
library(exactextractr)
library(matrixStats)
library(rgeos)
library(rmapshaper)
library(geojsonio)
library(plyr)
library(spatialEco)
slvShp <- st_read(dsn = "C:/Users/jmjimenez/Downloads/valor_ref_2020", layer = "Valor_Ref_M")
View(slvShp)
View(slvShp)
View(slvShp)
View(slvShp)
set.seed(1)
rm(list = ls())
library(grf)
if(packageVersion("grf") < '0.10.2') {
warning("This script requires grf 0.10.2 or higher")
}
library(sandwich)
library(lmtest)
library(Hmisc)
library(ggplot2)
library(Rcpp)
data.all = read.csv("C:/Users/jmjimenez/Downloads/synthetic_data.csv")
data.all$schoolid = factor(data.all$schoolid)
DF = data.all[,-1]
school.id = as.numeric(data.all$schoolid)
school.mat = model.matrix(~ schoolid + 0, data = data.all)
school.size = colSums(school.mat)
# It appears that school ID does not affect pscore. So ignore it
# in modeling, and just treat it as source of per-cluster error.
w.lm = glm(Z ~ ., data = data.all[,-3], family = binomial)
summary(w.lm)
W = DF$Z
Y = DF$Y
X.raw = DF[,-(1:2)]
C1.exp = model.matrix(~ factor(X.raw$C1) + 0)
View(C1.exp)
dr.score = tau.hat + W / cf$W.hat *
(Y - cf$Y.hat - (1 - cf$W.hat) * tau.hat) -
(1 - W) / (1 - cf$W.hat) * (Y - cf$Y.hat + cf$W.hat * tau.hat)
# Notes:
# - The paper refers to an argument called `samples.per.cluster`. This option was removed in grf version 1.0
# and is now by default (`equalize.cluster.weights = FALSE`) internally set to the size of the largest cluster,
# which means that large schools recieve larger weight than small schools. To be closer to the original behavior,
# this script has been updated by setting `equalize.cluster.weights` to TRUE, which means each school receives
# equal weight in ATE estimation.
#
# For more details on clustering in grf, see the algorithm reference at:
# https://grf-labs.github.io/grf/REFERENCE.html#cluster-robust-estimation
set.seed(1)
rm(list = ls())
library(grf)
if(packageVersion("grf") < '0.10.2') {
warning("This script requires grf 0.10.2 or higher")
}
library(sandwich)
library(lmtest)
library(Hmisc)
library(ggplot2)
library(Rcpp)
data.all = read.csv("C:/Users/jmjimenez/Downloads/synthetic_data.csv")
data.all$schoolid = factor(data.all$schoolid)
DF = data.all[,-1]
school.id = as.numeric(data.all$schoolid)
school.mat = model.matrix(~ schoolid + 0, data = data.all)
school.size = colSums(school.mat)
# It appears that school ID does not affect pscore. So ignore it
# in modeling, and just treat it as source of per-cluster error.
w.lm = glm(Z ~ ., data = data.all[,-3], family = binomial)
summary(w.lm)
W = DF$Z
Y = DF$Y
X.raw = DF[,-(1:2)]
C1.exp = model.matrix(~ factor(X.raw$C1) + 0)
XC.exp = model.matrix(~ factor(X.raw$XC) + 0)
X = cbind(X.raw[,-which(names(X.raw) %in% c("C1", "XC"))], C1.exp, XC.exp)
#
# Grow a forest. Add extra trees for the causal forest.
#
Y.forest = regression_forest(X, Y, clusters = school.id, equalize.cluster.weights = TRUE)
Y.hat = predict(Y.forest)$predictions
W.forest = regression_forest(X, W, clusters = school.id, equalize.cluster.weights = TRUE)
W.hat = predict(W.forest)$predictions
cf.raw = causal_forest(X, Y, W,
Y.hat = Y.hat, W.hat = W.hat,
clusters = school.id,
equalize.cluster.weights = TRUE)
varimp = variable_importance(cf.raw)
selected.idx = which(varimp > mean(varimp))
cf = causal_forest(X[,selected.idx], Y, W,
Y.hat = Y.hat, W.hat = W.hat,
clusters = school.id,
equalize.cluster.weights = TRUE,
tune.parameters = "all")
tau.hat = predict(cf)$predictions
#
# Estimate ATE
#
ATE = average_treatment_effect(cf)
paste("95% CI for the ATE:", round(ATE[1], 3),
"+/-", round(qnorm(0.975) * ATE[2], 3))
#
# Omnibus tests for heterogeneity
#
# Run best linear predictor analysis
test_calibration(cf)
# Compare regions with high and low estimated CATEs
high_effect = tau.hat > median(tau.hat)
ate.high = average_treatment_effect(cf, subset = high_effect)
ate.low = average_treatment_effect(cf, subset = !high_effect)
paste("95% CI for difference in ATE:",
round(ate.high[1] - ate.low[1], 3), "+/-",
round(qnorm(0.975) * sqrt(ate.high[2]^2 + ate.low[2]^2), 3))
dr.score = tau.hat + W / cf$W.hat *
(Y - cf$Y.hat - (1 - cf$W.hat) * tau.hat) -
(1 - W) / (1 - cf$W.hat) * (Y - cf$Y.hat + cf$W.hat * tau.hat)
set.seed(1)
rm(list = ls())
library(grf)
if(packageVersion("grf") < '0.10.2') {
warning("This script requires grf 0.10.2 or higher")
}
library(sandwich)
library(lmtest)
library(Hmisc)
library(ggplot2)
library(Rcpp)
data.all = read.csv("C:/Users/jmjimenez/Downloads/synthetic_data.csv")
data.all$schoolid = factor(data.all$schoolid)
DF = data.all[,-1]
school.id = as.numeric(data.all$schoolid)
source('~/.active-rstudio-document', echo=TRUE)
# Notes:
# - The paper refers to an argument called `samples.per.cluster`. This option was removed in grf version 1.0
# and is now by default (`equalize.cluster.weights = FALSE`) internally set to the size of the largest cluster,
# which means that large schools recieve larger weight than small schools. To be closer to the original behavior,
# this script has been updated by setting `equalize.cluster.weights` to TRUE, which means each school receives
# equal weight in ATE estimation.
#
# For more details on clustering in grf, see the algorithm reference at:
# https://grf-labs.github.io/grf/REFERENCE.html#cluster-robust-estimation
set.seed(1)
rm(list = ls())
library(grf)
if(packageVersion("grf") < '0.10.2') {
warning("This script requires grf 0.10.2 or higher")
}
library(sandwich)
library(lmtest)
library(Hmisc)
library(ggplot2)
library(Rcpp)
data.all = read.csv("C:/Users/jmjimenez/Downloads/synthetic_data.csv")
data.all$schoolid = factor(data.all$schoolid)
DF = data.all[,-1]
school.id = as.numeric(data.all$schoolid)
school.mat = model.matrix(~ schoolid + 0, data = data.all)
school.size = colSums(school.mat)
# It appears that school ID does not affect pscore. So ignore it
# in modeling, and just treat it as source of per-cluster error.
w.lm = glm(Z ~ ., data = data.all[,-3], family = binomial)
summary(w.lm)
W = DF$Z
Y = DF$Y
X.raw = DF[,-(1:2)]
C1.exp = model.matrix(~ factor(X.raw$C1) + 0)
XC.exp = model.matrix(~ factor(X.raw$XC) + 0)
X = cbind(X.raw[,-which(names(X.raw) %in% c("C1", "XC"))], C1.exp, XC.exp)
#
# Grow a forest. Add extra trees for the causal forest.
#
Y.forest = regression_forest(X, Y, clusters = school.id, equalize.cluster.weights = TRUE)
Y.hat = predict(Y.forest)$predictions
W.forest = regression_forest(X, W, clusters = school.id, equalize.cluster.weights = TRUE)
W.hat = predict(W.forest)$predictions
cf.raw = causal_forest(X, Y, W,
Y.hat = Y.hat, W.hat = W.hat,
clusters = school.id,
equalize.cluster.weights = TRUE)
varimp = variable_importance(cf.raw)
selected.idx = which(varimp > mean(varimp))
cf = causal_forest(X[,selected.idx], Y, W,
Y.hat = Y.hat, W.hat = W.hat,
clusters = school.id,
equalize.cluster.weights = TRUE,
tune.parameters = "all")
tau.hat = predict(cf)$predictions
ATE = average_treatment_effect(cf)
paste("95% CI for the ATE:", round(ATE[1], 3),
"+/-", round(qnorm(0.975) * ATE[2], 3))
test_calibration(cf)
school.size
View(X)
